3 非监督学习

特征缩放，MinMax等等会受异常值影响，Linear Regression和Trees不会受特征缩放的影响，基于距离的会

特征选择，有filter层和wrapper层，filter层是定义选择指标（information gain, variance, entropy, relevence, usefulness），wrapping层是选择算法，比如greedy, randomization

PCA

How to determin the principal component

* principal component of a dataset is the direction that has the largest variance , because it retains maximum amount of information in original data (minimize information loss)

get latent features

dimensionality reduction

* visualize high-dimensional data
* reduce noise
* make other algorithms work better 