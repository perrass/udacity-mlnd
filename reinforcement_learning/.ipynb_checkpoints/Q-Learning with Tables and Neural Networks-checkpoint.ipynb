{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-16 15:57:31,117] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
    "lr = .8\n",
    "y = .95\n",
    "num_episodes = 2000\n",
    "\n",
    "# create lists to contain total rewards and steps per episode\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    while j < 99:\n",
    "        j += 1\n",
    "        \n",
    "        # choose an action by greedily (with noise) picking from Q table\n",
    "        a = np.argmax(Q[s, :] + np.random.randn(1, env.action_space.n) * (1. / (i + 1)))\n",
    "        s1, r, d, _ = env.step(a)\n",
    "        Q[s, a] = Q[s, a] + lr * (r + y * np.max(Q[s1, :]) - Q[s, a])\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.5335\n"
     ]
    }
   ],
   "source": [
    "print(\"Score over time: \" + str(sum(rList) / num_episodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[  1.74842455e-01   6.46027534e-03   6.63106862e-03   6.49001787e-03]\n",
      " [  5.35662027e-04   9.48100586e-04   2.08466267e-03   1.77864344e-01]\n",
      " [  5.70232551e-03   1.79915618e-01   3.12173788e-03   5.47115543e-03]\n",
      " [  1.93596860e-04   5.09202784e-04   1.04723068e-03   6.41105870e-02]\n",
      " [  1.66159462e-01   1.40649692e-03   1.27550276e-03   2.40028341e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  1.65166837e-01   8.36652958e-04   2.11790273e-05   1.27967639e-06]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  3.01077426e-03   9.79150732e-04   5.01965198e-04   1.44819301e-01]\n",
      " [  0.00000000e+00   1.86055136e-01   1.83455986e-03   0.00000000e+00]\n",
      " [  2.56206422e-01   1.17317984e-04   3.44158457e-05   1.20696355e-04]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   3.83676572e-03   5.17124206e-01   4.07335507e-03]\n",
      " [  0.00000000e+00   0.00000000e+00   8.55779927e-01   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Q-Table Values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-learning with NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs1 = tf.placeholder(shape=[1, 16], dtype=tf.float32)\n",
    "W = tf.Variable(tf.random_uniform([16, 4], 0, 0.01))\n",
    "Qout = tf.matmul(inputs1, W)\n",
    "predict = tf.argmax(Qout, 1)\n",
    "\n",
    "nextQ = tf.placeholder(shape=[1, 4], dtype=tf.float32)\n",
    "loss = tf.reduce_sum(tf.square(nextQ - Qout))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of successful episodes: 0.4565%\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "y = .99\n",
    "e = .1\n",
    "num_episodes = 2000\n",
    "jList = []\n",
    "rList = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(num_episodes):\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        while j < 99:\n",
    "            j += 1\n",
    "            a, allQ = sess.run([predict, Qout], feed_dict={inputs1: np.identity(16)[s: s + 1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "            s1, r, d, _ = env.step(a[0])\n",
    "            Q1 = sess.run(Qout, feed_dict={inputs1: np.identity(16)[s1: s1 + 1]})\n",
    "            maxQ1 = np.max(Q1)\n",
    "            targetQ = allQ\n",
    "            targetQ[0, a[0]] = r + y * maxQ1\n",
    "            _, W1 = sess.run([updateModel, W], feed_dict={inputs1: np.identity(16)[s: s + 1], nextQ: targetQ})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            if d == True:\n",
    "                e = 1. / (i/50 + 10)\n",
    "                break\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        \n",
    "print(\"Percent of successful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(jList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(rList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
